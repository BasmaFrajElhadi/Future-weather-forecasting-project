{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future weather forecasting project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### My project is a forecast of the weather in the future, and although it appears to be an easy project, it is not really so. Trying to predict the weather and getting an approximate value is considered an achievement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be collected (scraping) from the website [Wunderground](https://www.wunderground.com/).And i will use Selenium framework and a Chrome browser to scrape the data from the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New York City was chosen to be a source of data from the station (LAGUARDIA AIRPORT STATION|CHANGE) because America is one of the leading countries in meteorology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Selenium WebDriver\n",
    "\n",
    "chrome_options = Options()\n",
    "# Enable headless mode\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "browser = webdriver.Chrome(options=chrome_options)\n",
    "wait = WebDriverWait(browser, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a DataFrame to store the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Date','Humidity_Avg','Wind_Type','Pressure_Avg'\n",
    ",'Condition','Temperature_Avg','Temperature_Historic','Precipitatio_Actual',\n",
    "'Precipitation_Historic','Dew_Point' ,'Max_Wind_Speed' ,'Sea_Level_Pressure' ,'Day_Length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_web_element_data(column_name , xpath, df_index):\n",
    "    \"\"\" \n",
    "    Scrapes data from a website and saves it into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        column_name (str): The name of the column in the DataFrame where the scraped data will be saved.\n",
    "        xpath (str): The XPath of the element from which data will be scraped on the website.\n",
    "        df_index (int): The index of the last row in the DataFrame, so the scraped data can be appended.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        element = wait.until(EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "        df.loc[df_index, column_name] = element.text\n",
    "    except:\n",
    "        df.loc[df_index, column_name] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_weather_table(weather_table,df_index):\n",
    "    \"\"\"\n",
    "    Calculate the mode of the data from a scraped weather table.\n",
    "\n",
    "    Args:\n",
    "        weather_table (webElement): A web element representing a table containing important data.\n",
    "        df_index (int): The index of the last row in the DataFrame, allowing the scraped data to be appended.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    humidity_list = wind_type_list =pressure_list = condition_list = None\n",
    "    # If the weather_table does exist on the site\n",
    "    if weather_table:\n",
    "        weather_rows = weather_table.text.strip().split('\\n')[10:]\n",
    "        weather_data = [row.split() for row in weather_rows]\n",
    "        humidity_list = [values[6] + ' ' + values[7] for values in weather_data]\n",
    "        wind_type_list = [values[8] for values in weather_data]\n",
    "        pressure_list = [values[13] + ' ' + values[14] for values in weather_data]\n",
    "        condition_list = [values[17] + ' ' + values[18] if len(values) > 18 else values[17] for values in weather_data]\n",
    "\n",
    "    # The site displays data every hour for 24 hours a day.\n",
    "    # I preferre to take the mode of these values for the entire day\n",
    "    df.loc[df_index, 'Humidity_Avg'] = statistics.mode(humidity_list)\n",
    "    df.loc[df_index, 'Wind_Type'] = statistics.mode(wind_type_list)\n",
    "    df.loc[df_index, 'Pressure_Avg'] = statistics.mode(pressure_list)\n",
    "    df.loc[df_index, 'Condition'] = statistics.mode(condition_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data_for_date(browser, wait, current_date,df_index):\n",
    "    \"\"\"\n",
    "    scrap data from the site for specific date\n",
    "\n",
    "    Args:\n",
    "        browser (webdriver): A webdriver object\n",
    "        wait (WebDriverWait object): the WebDriverWait object for how many waithing for site \n",
    "        df_index (int): The index of the last row in the DataFrame, allowing the scraped data to be appended.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Print the current_date just to see the progress of the scraping\n",
    "    print(f\"Scraping data for {current_date}\")\n",
    "    try:\n",
    "        browser.get(f'https://www.wunderground.com/history/daily/us/ny/new-york-city/KLGA/date/{current_date}')\n",
    "        df.loc[df_index, 'Date'] = current_date\n",
    "        get_web_element_data('Temperature_Avg','//*[@id=\"inner-content\"]/div[2]/div[1]/div[3]/div[1]/div/lib-city-history-summary/div/div[2]/table/tbody[1]/tr[3]/td[1]',df_index)\n",
    "        get_web_element_data('Temperature_Historic','//*[@id=\"inner-content\"]/div[2]/div[1]/div[3]/div[1]/div/lib-city-history-summary/div/div[2]/table/tbody[1]/tr[3]/td[2]',df_index)\n",
    "        get_web_element_data('Precipitatio_Actual','//*[@id=\"inner-content\"]/div[2]/div[1]/div[3]/div[1]/div/lib-city-history-summary/div/div[2]/table/tbody[2]/tr/td[1]',df_index)\n",
    "        get_web_element_data('Precipitation_Historic','//*[@id=\"inner-content\"]/div[2]/div[1]/div[3]/div[1]/div/lib-city-history-summary/div/div[2]/table/tbody[2]/tr/td[1]',df_index)\n",
    "        get_web_element_data('Precipitatio_Actual','//*[@id=\"inner-content\"]/div[2]/div[1]/div[3]/div[1]/div/lib-city-history-summary/div/div[2]/table/tbody[2]/tr/td[2]',df_index)\n",
    "        get_web_element_data('Dew_Point','//*[@id=\"inner-content\"]/div[2]/div[1]/div[3]/div[1]/div/lib-city-history-summary/div/div[2]/table/tbody[3]/tr[1]/td[1]',df_index)\n",
    "        get_web_element_data('Max_Wind_Speed','//*[@id=\"inner-content\"]/div[2]/div[1]/div[3]/div[1]/div/lib-city-history-summary/div/div[2]/table/tbody[4]/tr[1]/td[1]',df_index)\n",
    "        get_web_element_data('Sea_Level_Pressure','//*[@id=\"inner-content\"]/div[2]/div[1]/div[3]/div[1]/div/lib-city-history-summary/div/div[2]/table/tbody[5]/tr/td[1]',df_index)\n",
    "        get_web_element_data('Day_Length','//*[@id=\"inner-content\"]/div[2]/div[1]/div[3]/div[1]/div/lib-city-history-summary/div/div[2]/table/tbody[6]/tr[1]/td[1]',df_index)\n",
    "        \n",
    "        try:\n",
    "            weather_table = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'mat-table')))\n",
    "        except:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "            weather_table = None\n",
    "        finally:\n",
    "            get_data_from_weather_table(weather_table,df_index)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Scrapes data from the site for a range of dates.\n",
    "\n",
    "    Args:\n",
    "        start_date (datetime): The start date for scraping, as a datetime object.\n",
    "        end_date (datetime): The end date for scraping, as a datetime object.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Get the current length of the DataFrame to determine the last index and append data accordingly\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        df_index = len(df.index)\n",
    "        scrape_data_for_date(browser, wait, current_date,df_index)\n",
    "        # Increment current_date by one day\n",
    "        current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time range for data scraping\n",
    "start_date = datetime(2009,1,1)\n",
    "end_date = datetime(2023, 12, 30)\n",
    "\n",
    "# start Scraping\n",
    "scrape_data(start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the data to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('weather.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close the browser driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebfc0a8d552866b0d59eba665220a57de3bc06f3ac643b8bef38dd8f66781fdd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
